# crawling-repo-3

무신사 데이터 크롤링

### 데이터 수집의 개요
- 수집 목적, 동기
: 무신사 웹사이트에서 옷 데이터를 수집
: 원하는 옷을 찾아주겠다?


### 데이터 수집 계획
- 데이터 수집의 스케쥴
- 몇 개의 서버로 각각 얼마의 주기로 데이터 크롤링. 
: 아이템 크롤링 서버 2개, 매주 업데이트?
: db 1개, s3
: aws lambda로 스케쥴 관리

### 데이터의 저장
mysql


### 코드 관리
- requirements.txt


### 프로젝트 회고
: 1주차 : 최대한 적은 리소스를 활용하여 스크래피와 셀레니움을 전부 활용하는 방법을 찾는 것이 어려웠다. t2.micro 서버 1개가 셀레니움 드라이버 1개, 스크래피 90개의 리퀘스트 이상의 작업을 하면 다운되어 버려서 자주 서버를 껐다 켰다. cpu, ram의 10% 여유를 두고 최대 허용 범위내에서 작업이 가능하게 하려고 노력하였다.